{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enonc√© du probl√®me\n",
    "\n",
    "L'objectif de ce projet est d'estimer la longueur de c√¢ble sous-marin n√©cessaire pour relier deux c√¥tes $A$ et $B$  en utilisant des simulations conditionnelles.\n",
    "\n",
    "\n",
    "Le c√¢ble reposera sur le fond marin dont la profondeur est inconnue.\n",
    "Le segment $[AB]$ est discr√©tis√© par une s√©quence de (N+1) points. On pose $x_0=A$ et pour $i=1,\\dots,N$, $$x_i=x_0+i\\Delta$$ o√π $$\\Delta = \\frac{AB}{N}$$ de telle sorte que $x_N=B$.\n",
    "On note $z(x)$ la profondeur du fond marin au point $x$ de telle sorte \n",
    "qu'on pourra estimer la longueur totale de c√¢ble n√©cessaire par la somme \n",
    "des longueurs sur les segments de la discr√©tisation :\n",
    "\n",
    "$$l=\\sum_{i=1}^N\\sqrt{\\Delta^2+(z(x_i)-z(x_{i-1}))^2}.$$\n",
    "\n",
    "Enfin, notons que l'on dispose d'un ensemble de $n$ observations de la \n",
    "profondeur que l'on supposera situ√©es sur des points de discr√©tisation $z(x_{j_1}),\\dots,z(x_{j_n})$.\n",
    "\n",
    "\n",
    "On adopte un mod√®le probabiliste pour la profondeur. On suppose que le vecteur des \n",
    "profondeurs sur les points de discr√©tisation \n",
    "$\\mathbf{z}=(z(x_0),\\dots,z(x_N))$ est la r√©alisation\n",
    "d'un vecteur al√©atoire gaussien $\\mathbf{Z}=(Z(x_0),\\dots,Z(x_N))$ \n",
    "dont le vecteur d'esp√©rance ne contient qu'une seule valeur $\\mu$ \n",
    "r√©p√©t√©e $N+1$ fois et dont la matrice de covariance $\\Sigma$ a pour termes $\\sigma_{ij}$\n",
    "d√©finis par $\\sigma_{ij}=C(|x_i-x_j|)$ o√π $C$ est une\n",
    "fonction d√©croissante, traduisant le fait que deux points \n",
    "g√©ographiquement proches ont tendance √† avoir des profondeurs plus similaires que deux points √©loign√©s.\n",
    "\n",
    "On supposera que la matrice de covariance ainsi \n",
    "g√©n√©r√©e est d√©finie-positive (en fait, $C$ sera choisie parmi les fonctions qui, \n",
    "appliqu√©es aux termes d'une matrice de distance, produisent des matrices d√©finie-positives). \n",
    "\n",
    "Si on note $L$ la variable al√©atoire donnant la longueur de cable n√©cessaire : \n",
    "$$L=\\sum_{i=1}^N\\sqrt{\\Delta^2+(Z(x_i)-Z(x_{i-1}))^2},$$\n",
    "un bon estimateur de $L$ est fourni par l'esp√©rance conditionnelle \n",
    "\n",
    "$$L^\\star=E[L|Z(x_{j_1})=z(x_{j_1}),\\dots,Z(x_{j_n})=z(x_{j_n})].$$\n",
    "                                                                              \n",
    "Cependant, cette quantit√© est difficilement accessible par le calcul. \n",
    "On va donc avoir recours √† des\n",
    "simulations conditionnelles. C'est-√†-dire que l'on va simuler \n",
    "un nombre $K$ de r√©alit√©s (disons des r√©alisations du mod√®le \n",
    "probabiliste choisi), et sur chacune d'entre elle, \n",
    "la quantit√© de c√¢ble n√©cessaire sera √©valu√©e. \n",
    "On disposera ainsi d'un √©chantillon $l_{(1)},\\dots,l_{(K)}$ de \n",
    "longueures simul√©es. Puis on approchera l'esp√©rance conditionnelle  par \n",
    "$$L^\\star= \\frac{1}{K}\\sum_{k=1}^K l_{(k)}.$$\n",
    "\n",
    "L'objectif de ce projet est donc d'√©crire un code permettant \n",
    "d'effectuer cette simulation conditionnelle, puis de l'appliquer \n",
    "au jeu de donn√©es fourni et d'en d√©duire une estimation de la longueur de c√¢ble n√©cessaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions th√©oriques\n",
    "\n",
    "1. Quel th√©or√®me du cours nous autorise-t-il √† estimer l'esp√©rance conditionnelle par la moyenne empirique de simulations conditionnelles ?\n",
    "\n",
    "2. Rappeler la loi conditionnelle du vecteur des composantes de $\\mathbf{Z}$ correspondant aux points de discr√©tisation\n",
    "sans observation, connaissant les valeurs prises par les composantes aux sites d'observation.\n",
    "\n",
    "3. Si $\\mathbf{Y}=(Y_1,\\dots,Y_p)$ est un vecteur de composantes gaussiennes ind√©pendantes, toutes d'esp√©rance nulle et de variance 1, \n",
    "quelle est la loi du vecteur $\\mathbf{Z}=m+R\\mathbf{Y}$ o√π $R$ est une matrice $p\\times p$ et $m$ est un vecteur de taille $p$ ?\n",
    "\n",
    "4. En d√©duire un algorithme de simulation conditionnelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. C'est la loi forte des grands nombres qui assure que $$\\lim\\limits_{K \\to \\infty}\\frac{1}{K}\\sum_{k=1}^K l_{(k)}=L^*$$\n",
    "\n",
    "On peut l'appliquer ici car les variables al√©atoires $l_{(k)}$ sont ind√©pendantes, de m√™me loi et de carr√© int√©grable car ce sont des sommes finies de variables al√©atoires prenant des valeurs finies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Notons X (resp. Y) le sous-vecteur al√©atoire de Z correspondant aux points de discr√©tisation avec (resp. sans) observation.\n",
    "\n",
    "Alors d'apr√®s le cours, on a directement que $\\forall x \\in \\mathbb{R}^n$ la variable al√©atoire $Y|X=z$ est gaussienne d'esp√©rance $m_{Y|X=z} = \\psi(z) = m_Y + C_{Y,X}C_X^{-1}(z-m_X)$ et de matrice de covariance $CS_Y = C_Y - C_{Y,X}C_X^{-1}C_{X,Y}$. Autrement dit, l'esp√©rance conditionnelle de $Y$ sachant $X$ est la variable al√©atoire $Esp(Y|X) = \\psi(X) =(m_Y + C_{Y,X}C_X^{-1}(X-m_X))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Si $\\mathbf{Z}=m+R\\mathbf{Y}$ alors $\\mathbf{Z}$ est gaussien comme\n",
    "combinaison lin√©aire de variables al√©atoires gaussiennes,\n",
    "$(\\mathbb{E}(Z) = \\mathbb{E}(m + R\\mathbf{Y}) = m)$ et$\n",
    "(\\mathbb{V}(Z) = \\mathbb{E}((L\\,\\mathbf{Y})^2) = R I_d R^t =RR^t ).$\n",
    "\n",
    "Donc $\\mathbf{Z}$ est gaussien de vecteur d'esp√©rance $m$ et de matrice de covariance $RR^t=C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. L'algorithme de simulation conditionnelle que nous allons alors mettre en oeuvre est le suivant:\n",
    "-On calcule la matrice de Covariance Œ£\n",
    "\n",
    "-On simule le vecteur Y de composantes gaussiennes ind√©pendantes, toutes d'esp√©rance nulle et de variance 1 gr√¢ce √† la m√©thode  de Box-Muller\n",
    "\n",
    "-On calcule la factorisation de Cholesky de Œ£ (possible car Œ£ est d√©finie-positive par hypoth√®se et sym√©trique par construction), on appelle R la matrice triangulaire inf√©rieure ainsie obtenue.\n",
    "\n",
    "-On peut alors simuler le vecteur al√©atoire $\\mathbf{Z}=(z(x_0),\\dots,z(x_N))$ puisque $\\mathbf{z}=\\begin{pmatrix}ùúá \\\\ \\vdots\\\\ùúá \\end{pmatrix} + RY $\n",
    "\n",
    "-On utilise finalement la formule de la question 2 pour r√©aliser les simulations conditionnelles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donn√©es du probl√®me\n",
    "Conventionnellement, $A$ est l'origine, $B=500$, $N=100$.\n",
    "\n",
    "Les donn√©es $$\\begin{array}{c|r}i & z(x_i)\\\\\n",
    "\\hline\n",
    "0 & 0\\\\\n",
    "20 & -4\\\\\n",
    "40 & -12.8\\\\\n",
    "60 & -1\\\\\n",
    "80 & -6.5\\\\\n",
    "100 & 0\\end{array}$$\n",
    "\n",
    "L'esp√©rance de chaque composante du vecteur al√©atoire $\\mathbf{Z}$ est donn√©e par $\\mu=-5.$\n",
    "\n",
    "La fonction $C$ est d√©finie par $$C(h)=\\sigma^2 e^{-|h|/a},$$\n",
    "\n",
    "o√π $|h|$ correspond √† la distance entre deux points, $a=50$ et $\\sigma^2=12$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impl√©mentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©ambule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement de d√©pendances\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Discr√©tisation\n",
    "A=0\n",
    "B=500\n",
    "N=101 #Nombre de points de discr√©tisation\n",
    "Delta = (B-A)/(N-1)\n",
    "discretization_indexes = np.arange(N)\n",
    "discretization = discretization_indexes*Delta\n",
    "#Param√®tres du mod√®le\n",
    "\n",
    "mu=-5\n",
    "a = 50\n",
    "sigma2 = 12\n",
    "\n",
    "#Donn√©es\n",
    "\n",
    "observation_indexes = [0,20,40,60,80,100]\n",
    "depth = np.array([0,-4,-12.8,-1,-6.5,0])\n",
    "\n",
    "#Indices des composantes correspondant aux observations et aux componsantes non observ√©es\n",
    "\n",
    "unknown_indexes=list(set(discretization_indexes)-set(observation_indexes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1. Ecrire une fonction qui prend en argument la distance entre les points, le param√®tre $a$, et le param√®tre $\\sigma^2$, et qui retourne la covariance entre deux points.\n",
    "On pourra fournir une matrice de distance √† cette fonction. Dans ce cas, la fonction renverra la matrice de covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(d,a,sigma_carr√©):\n",
    "    return sigma_carr√©*np.exp(-abs(d)/a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculer la matrice de distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.zeros((N,N))    \n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        distance[i][j] = Delta*abs(i-j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculer la matrice de covariance du vecteur $\\mathbf{Z}=(Z(x_0),\\dots,Z(x_N))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = covariance(distance,a,sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extraire les 3 matrices de covariance suivantes :\n",
    "\n",
    " * entre les observations\n",
    "\n",
    " * entre les observations et les inconnues\n",
    "\n",
    " * entre les inconnues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_observable = np.array([i in observation_indexes for i in range(N)])\n",
    "cache_inconnues = np.array([i in unknown_indexes for i in range(N)])\n",
    "\n",
    "covariance_observables = cov[cache_observable,:][:,cache_observable]\n",
    "covariance_observables_inconnues = cov[cache_observable,:][:,cache_inconnues]\n",
    "covariance_inconnues_observables = cov[cache_inconnues,:][:,cache_observable]\n",
    "covariance_inconnues = cov[cache_inconnues,:][:,cache_inconnues]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculer l'esp√©rance conditionnelle des composantes non observ√©es connaissant les observations et la repr√©senter avec les donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([mu for i in range(N)])\n",
    "mobs = m[observation_indexes]\n",
    "minc = m[unknown_indexes]\n",
    "\n",
    "esperance = minc + np.dot(covariance_inconnues_observables,np.dot(np.linalg.inv(covariance_observables),depth-mobs))\n",
    "\n",
    "#On cherche √† remettre les points connus au milieu des points estim√©s\n",
    "#Pour cela on d√©cide de mettre tous les points dans la m√™me liste d'abord ceux connus puis ceux inconnus\n",
    "#Puis on cr√©e une liste permutation qui permet de remettre les points dans l'ordre\n",
    "#L'int√©r√™t est que la cr√©ation de la liste est en O(N^2) mais tous les appels √† la fonction seront en O(N)\n",
    "\n",
    "ordre = observation_indexes + unknown_indexes\n",
    "permutation = np.array([ordre.index(i) for i in range(N)])\n",
    "\n",
    "def insertion_points(depth,inconnus):\n",
    "    hauteurs = np.concatenate((depth,inconnus))\n",
    "    return hauteurs[permutation]\n",
    "\n",
    "cable_esp = insertion_points(depth,esperance)\n",
    "abscisses = 5*np.arange(0,N)\n",
    "\n",
    "plt.plot(abscisses,cable_esp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Calculer la matrice de variance conditionnelle et tracer sa diagonale (variance conditionnelle) en fonction de la position. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_conditionnelle = covariance_inconnues - np.dot(covariance_inconnues_observables,np.dot(np.linalg.inv(covariance_observables),covariance_observables_inconnues))\n",
    "variance_conditionnelle = np.diag(covariance_conditionnelle)\n",
    "variance_connues = [0 for i in depth]\n",
    "variance = insertion_points(variance_connues,variance_conditionnelle)\n",
    "\n",
    "plt.plot(abscisses,variance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus on s'√©loigne des points connus, plus la variance augmente. Cela correspond au fait qu'on ait plus d'incertitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Effectuer une simulation conditionnelle. Sur un m√™me graphique, tracer la simulation ainsi que les donn√©es et l'esp√©rance conditionnelle. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On impl√©mente l'algorithme d√©crit √† la question 4\n",
    "\n",
    "#On calcule la d√©composition de Choleski de la covariance pour appliquer la formule de la question 3\n",
    "R = np.linalg.cholesky(covariance_conditionnelle)\n",
    "\n",
    "def simulation():\n",
    "    sim_uniforme1 = np.array(np.random.random(len(unknown_indexes)))\n",
    "    sim_uniforme2 = np.array(np.random.random(len(unknown_indexes)))\n",
    "    sim_gaussienne_centr√©e_r√©duite = np.sqrt(-2*np.log(sim_uniforme1)) * np.cos(2*np.pi*sim_uniforme2)\n",
    "    sim_inconnues = mu + np.dot(R,sim_gaussienne_centr√©e_r√©duite)\n",
    "    return insertion_points(depth,sim_inconnues)\n",
    "\n",
    "sim = simulation()\n",
    "\n",
    "plt.plot(abscisses,sim)\n",
    "plt.plot(abscisses,cable_esp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variations des simulations sont beaucoup plus violentes, cela cr√©e de la longueur de cable en plus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Ecrire une fonction qui calcule la longueur du c√¢ble en fonction du vecteur des profondeurs et du pas de discr√©tisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longueur(profondeurs,pas):\n",
    "    return np.sum(np.sqrt((profondeurs[1:]-profondeurs[:-1])**2+pas**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Utiliser cette fonction pour calculer la longueur du c√¢ble √† partir de 100 simulations. Comparer l'esp√©rance conditionnelle (estim√©e) de la longueur avec la longueur de l'esp√©rance conditionnelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_simulations = 100\n",
    "\n",
    "longueurs_sim = np.array([longueur(simulation(),Delta) for i in range(nb_simulations)])\n",
    "\n",
    "print(f\"Esp√©rance conditionnelle de la longueur : {np.mean(longueurs_sim)}\")\n",
    "print(f\"Longueur de l'esp√©rance conditionnelle : {longueur(cable_esp,Delta)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'esp√©rance conditionnelle de la longueur est largement sup√©rieure √† la longueur de l'esp√©rance conditionnelle. Cela semble normal puisque sur les simulations le cable a tendance √† avoir des variations plus violentes que l'esp√©rance conditionnelle de la longueur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Repr√©senter la suite $M_n$ des moyennes des longueurs de c√¢bles en fonction du nombre de simulations. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([np.mean([longueur(simulation(),Delta) for i in range(j)]) for j in range(1,nb_simulations)])\n",
    "\n",
    "plt.plot(np.arange(1,nb_simulations),M)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suite semble converger autour de 536 m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Repr√©senter l'histogramme des longueurs de c√¢bles g√©n√©r√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(longueurs_sim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Donner un intervalle de confiance √† 95% de la longueur du c√¢ble par 2 m√©thodes diff√©rentes. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M√©thode 1: \n",
    "#On sort les 2,5% des plus petites et des plus grandes valeurs pour estimer que 95% des valeurs sont dans l'intervalle\n",
    "longueurs_sim.sort()\n",
    "print(f\"Intervalle de confiance 1 : [{longueurs_sim[int(0.025*nb_simulations)]},{longueurs_sim[int(0.975*nb_simulations)]}]\")\n",
    "\n",
    "#M√©thode 2:\n",
    "#On calcule l'intervalle avec la formule vue en Terminale : [moyenne -/+ 1.96*ecart_type/sqrt(nombre de simulation)]\n",
    "\n",
    "moyenne = np.mean(longueurs_sim)\n",
    "ecart_type  = np.sqrt(1/nb_simulations*np.sum((longueurs_sim - moyenne)**2))\n",
    "print(f\"Intervalle de confiance 2 : [{moyenne - 1.96*ecart_type/np.sqrt(nb_simulations)},{moyenne + 1.96*ecart_type/np.sqrt(nb_simulations)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'intervalle de confiance \"√† la main\" est beaucoup plus large que celui calcul√© math√©matiquement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Donner une estimation de la probabilit√© que la longueur du c√¢ble d√©passe 525 m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(longueurs_sim>525)/nb_simulations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Reprendre les questions pr√©c√©dentes avec 1000, 10000 puis 100000 simulations. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_simulations = 1000\n",
    "\n",
    "longueurs_sim = np.array([longueur(simulation(),Delta) for i in range(nb_simulations)])\n",
    "\n",
    "print(f\"Esp√©rance conditionnelle de la longueur : {np.mean(longueurs_sim)}\")\n",
    "print(f\"Longueur de l'esp√©rance conditionnelle : {longueur(cable_esp,Delta)}\")\n",
    "\n",
    "M = np.array([np.mean([longueur(simulation(),Delta) for i in range(j)]) for j in range(1,nb_simulations)])\n",
    "\n",
    "#M√©thode 1: \n",
    "#On sort les 2,5% des plus petites et des plus grandes valeurs pour estimer que 95% des valeurs sont dans l'intervalle\n",
    "longueurs_sim.sort()\n",
    "print(f\"Intervalle de confiance 1 : [{longueurs_sim[int(0.025*nb_simulations)]},{longueurs_sim[int(0.975*nb_simulations)]}]\")\n",
    "\n",
    "#M√©thode 2:\n",
    "#On calcule l'intervalle avec la formule vue en Terminale : [moyenne -/+ 1.96*ecart_type/sqrt(nombre de simulation)]\n",
    "\n",
    "moyenne = np.mean(longueurs_sim)\n",
    "ecart_type  = np.sqrt(1/nb_simulations*np.sum((longueurs_sim - moyenne)**2))\n",
    "print(f\"Intervalle de confiance 2 : [{moyenne - 1.96*ecart_type/np.sqrt(nb_simulations)},{moyenne + 1.96*ecart_type/np.sqrt(nb_simulations)}]\")\n",
    "\n",
    "print(np.sum(longueurs_sim>525)/nb_simulations)\n",
    "\n",
    "fig,axes = plt.subplots(2)\n",
    "\n",
    "axes[0].plot(np.arange(1,nb_simulations),M)\n",
    "axes[1].hist(longueurs_sim)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_simulations = 10000\n",
    "\n",
    "longueurs_sim = np.array([longueur(simulation(),Delta) for i in range(nb_simulations)])\n",
    "\n",
    "print(f\"Esp√©rance conditionnelle de la longueur : {np.mean(longueurs_sim)}\")\n",
    "print(f\"Longueur de l'esp√©rance conditionnelle : {longueur(cable_esp,Delta)}\")\n",
    "\n",
    "M = np.array([np.mean([longueur(simulation(),Delta) for i in range(j)]) for j in range(1,nb_simulations)])\n",
    "\n",
    "#M√©thode 1: \n",
    "#On sort les 2,5% des plus petites et des plus grandes valeurs pour estimer que 95% des valeurs sont dans l'intervalle\n",
    "longueurs_sim.sort()\n",
    "print(f\"Intervalle de confiance 1 : [{longueurs_sim[int(0.025*nb_simulations)]},{longueurs_sim[int(0.975*nb_simulations)]}]\")\n",
    "\n",
    "#M√©thode 2:\n",
    "#On calcule l'intervalle avec la formule vue en Terminale : [moyenne -/+ 1.96*ecart_type/sqrt(nombre de simulation)]\n",
    "\n",
    "moyenne = np.mean(longueurs_sim)\n",
    "ecart_type  = np.sqrt(1/nb_simulations*np.sum((longueurs_sim - moyenne)**2))\n",
    "print(f\"Intervalle de confiance 2 : [{moyenne - 1.96*ecart_type/np.sqrt(nb_simulations)},{moyenne + 1.96*ecart_type/np.sqrt(nb_simulations)}]\")\n",
    "\n",
    "print(np.sum(longueurs_sim>525)/nb_simulations)\n",
    "\n",
    "fig,axes = plt.subplots(2)\n",
    "\n",
    "axes[0].plot(np.arange(1,nb_simulations),M)\n",
    "axes[1].hist(longueurs_sim)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_simulations = 100000\n",
    "\n",
    "longueurs_sim = np.array([longueur(simulation(),Delta) for i in range(nb_simulations)])\n",
    "\n",
    "print(f\"Esp√©rance conditionnelle de la longueur : {np.mean(longueurs_sim)}\")\n",
    "print(f\"Longueur de l'esp√©rance conditionnelle : {longueur(cable_esp,Delta)}\")\n",
    "\n",
    "M = np.array([np.mean([longueur(simulation(),Delta) for i in range(j)]) for j in range(1,nb_simulations)])\n",
    "\n",
    "#M√©thode 1: \n",
    "#On sort les 2,5% des plus petites et des plus grandes valeurs pour estimer que 95% des valeurs sont dans l'intervalle\n",
    "longueurs_sim.sort()\n",
    "print(f\"Intervalle de confiance 1 : [{longueurs_sim[int(0.025*nb_simulations)]},{longueurs_sim[int(0.975*nb_simulations)]}]\")\n",
    "\n",
    "#M√©thode 2:\n",
    "#On calcule l'intervalle avec la formule vue en Terminale : [moyenne -/+ 1.96*ecart_type/sqrt(nombre de simulation)]\n",
    "\n",
    "moyenne = np.mean(longueurs_sim)\n",
    "ecart_type  = np.sqrt(1/nb_simulations*np.sum((longueurs_sim - moyenne)**2))\n",
    "print(f\"Intervalle de confiance 2 : [{moyenne - 1.96*ecart_type/np.sqrt(nb_simulations)},{moyenne + 1.96*ecart_type/np.sqrt(nb_simulations)}]\")\n",
    "\n",
    "print(np.sum(longueurs_sim>525)/nb_simulations)\n",
    "\n",
    "fig,axes = plt.subplots(2)\n",
    "\n",
    "axes[0].plot(np.arange(1,nb_simulations),M)\n",
    "axes[1].hist(longueurs_sim)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'intervalle de confiance s'affine autour de l'esp√©rance lorsqu'on augmente le nombre de simulations"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "5ceb69a5bbd14071b254c2439a58ac4b",
   "lastKernelId": "0e923419-c540-42c1-ab5f-d0e05ff4521c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
